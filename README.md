# instagram-highload
ДЗ-1 по курсу Highload. Проектирование веб-сервиса Instagram

### 1. Тема
Instagram - приложение для обмена фотографиями с элементами социальной сети

* функционал по публикации фото, их комментированию, просмотру ленты
* 70% аудитории моложе 30 лет
* наиболее популярен в США, России и Бразилии

### 2. Планируемая нагрузка

* аудитория - 1 млрд. человек ([источник](https://tass.ru/ekonomika/5309458))
* около 500 млн. пользователей ежедневно ([источник](https://lpgenerator.ru/blog/2019/02/28/instagram-v-cifrah-statistika-na-2019-god/))
* среднее время, проведенное в Instagram - 28 мин./день ([источник](https://www.likeni.ru/analytics/statistika-po-instagram-kotoruyu-nuzhno-znat-k-2020-godu/))

Обычно, пользователь заходит на сайт по несколько раз в день.
Зная, что среднее время, проведенное в Instagram - 28 мин./день, предположим,
что пользователь заходит 7 раз в день, проводя на сайте по 4 минуты.

Теперь оценим трафик среднестатистического пользователя за одну сессию.

За 4 минуты пользования сайтом(просмотр ленты), я сделал 315 запросов и загрузил 33.8 мб данных.
Их них:
* на динамику - 75 запросов и 995 кб (~ 0.97 мб)
* на картинки - 211 запросов и 28.5 мб
* на остальную статику - 29 запросов и 4.3 мб

Тогда за сутки среднестатистический пользователь:
* для динамики <br/>
  * загрузит ```7 * 0.97 = 6.8 мб``` данных <br/>
  * сделает ```7 * 75 = 525``` запросов

* для картинок <br/>
  * загрузит ```7 * 28.5 = 199.5 мб``` данных <br/>
  * сделает ```7 * 211 = 1477``` запросов

* для остальной статики <br/>
  * загрузит ```7 * 4.3 = 30.1 мб``` данных <br/>
  * сделает ```7 * 29 = 203``` запроса

Расcчитаем средний трафик:
- динамика:```(6.8 мб * 500 000 000) * (8/1024) / (24 * 60 * 60) = 307.44 Гбит/с```
- картинки: ```(199.5 мб * 500 000 000) * (8/1024) / (24 * 60 * 60) = 9019.64 Гбит/c```
- остальная статика:```(30.1 мб * 500 000 000) * (8/1024) / (24 * 60 * 60) = 1360.86 Гбит/c```

Расcчитаем средний RPS:
- динамика: ```(525 * 500 000 000) / (24 * 60 * 60) = 3 038 195 RPS```
- картинки: ```(1477 * 500 000 000) / (24 * 60 * 60) = 8 547 454 RPS```
- остальная статика: ```(203 * 500 000 000) / (24 * 60 * 60) = 1 174 769 RPS```

Также, помимо просмотра ленты, сервис предоставляет функционал создания постов и комментариев лайков и 
авторизации/регистрации, нагрузки на сервисы которых также необходимо подсчитать.

Согласно [источнику](https://www.likeni.ru/analytics/statistika-po-instagram-kotoruyu-nuzhno-znat-k-2020-godu/), 
прирост аудитории Instagram на 2019 год составил 7,3%. Это значит, что за год произойдет 73 000 000
запросов на регистрацию, т.е.<br>
```73 000 000 / (365 * 24 * 60 * 60) = 2.4 RPS```. <br>
Предположив, что один такой запрос передает ~400 байт информации, получим<br>
```(400 байт * 73 000 000) * (8/1024) / (365 * 24 * 60 * 60) = 7.2 Кбит/с```<br>
Так как аудитория проекта составляет 500 млн. человек и мы приняли, что в среднем каждый их них заходит на сайт по 4 раза в день,
получаем 2 000 000 000 запросов на авторизацию в день, т.е. примерно <br>
```2 000 000 000 / (24 * 60 * 60) = 23 148 RPS```<br>
Запрос на авторизацию в Instagram передает 154 байта по сети, тогда нагрузка составит около<br>
```(154 байт * 2 000 000 000) * (8/1024/1024) / (24 * 60 * 60) = 27 Мбит/с```<br>

Тогда общая нагрузка на сервис авторизации/регистрации будет:
```7.2 Кбит/с + 27 Мбит/с = 28 Мбит/с```<br>
```2.4 + 23 148 = 23 151 RPS```

Примем, что в день публикуется 100 млн. постов ([источник](https://lpgenerator.ru/blog/2019/02/28/instagram-v-cifrah-statistika-na-2019-god/)),
т.е. ~1158 постов в секунду.
А также, ежесекундно ставится 8500 лайков и 1000 комментариев ([источник](https://www.likeni.ru/analytics/25-faktov-ob-instagram-kotorye-dolzhen-znat-kazhdyy/))
Примем, что в каждом посте публикуется по 1 фото, тогда объем переданных данных равен ~3 мб. 
При лайке поста передается 75 байт, а при публикации комментария ~ 450 - 600 байт. Тогда, можем рассчитать нагрузку:
* на посты ```(3 мб * 1158) * (8/1024) = 27.2 Гбит/с```
* на комментарии ```(600 байт * 1000) * (8/1024/1024) = 4.6 Мбит/с```
* на лайки ```(75 байт * 1000) * (8/1024/1024) = 0.6 Мбит/с```

Итого:<br>
```1158 + 8500 + 1000 = 10 658 RPS```<br>
```27.2 Гбит/с + 4.6 Мбит/с + 0.6 Мбит/с = 28 Гбит/с```

### 3. Логическая схема БД

![Схема бд](https://github.com/Alkirys/instagram-highload/blob/main/images/BD_logic.png "Схема бд")

### 4. Физические системы хранения

Для хранения данных о пользователях, постах, комментариях и лайках, я выбрал
СУБД PostgreSQL, как наиболее функциональную и надежную базу данных, имеющую хорошую поддержку
и инструменты шардинга.

Шардинг таблиц пользователей, и комментариев может производиться по полю id. Для таблицы постов, шардинг по id не 
подойдет, так как такое решение может сильно замедлить запрос на получение пользователем ленты, в данном случае, имеет 
смысл шардить посты по геопозиции.

Активные сессии пользователей для обеспечения скорейшего доступа будут храниться в Redis.
Также, Redis имеет возможность master-slave репликацию и встроенное API для работы с
Memcached.

Примерный расчет объема фото:

Согласно источникам([1](https://tjournal.ru/flood/48865-instagram-thanksgiving), [2](https://ru.epicstars.com/full_history_of_instagam/)) 
при аудитории в 100 млн. пользователей, в Instagram было опубликовано 16 млрд. фото.
Рассчитаем примерное количество фото для аудитории в 1 млрд. человек<br>
```(1 млрд. * 16 млрд.) / 100 млн. = 160 млрд.```
<br>
Тогда, приняв средний размер фото равный 2 мб, для их хранения понадобится<br>
```2 * 160000000000 / 1024 = 312 500 000 Гб```

Примерный расчет объема таблиц:

* Пользователи:<br>
Аудитория сервиса - 1 млрд. человек. Тогда одна запись в таблице займет:<br>
  ```4(user_id) + 128(username) + 128(password) + 128(email) + 128(avatar) + 4 * 150(subscribe) = 1116 байт```
  <br><br>
  А всего необходимо<br>
  ```1116 * 1000000000 / 1024^3  = 1040 Гб```<br><br>
  
* Посты:<br>
  Одна запись в таблице займет:<br>
  ```4(post_id) + 4(user_id) + 256(description) + 128(images_url) + 128(location) + 4(likes) = 524 байта```
  <br><br>
  Предположим, что каждый пост содержит одно фото, тогда всего таблица займет <br>
  ```524 * 160000000000 / 1024^3  = 78 083 Гб```<br><br>

* Комментарии:<br>
  Одна запись в таблице займет:<br>
  ```4(comment_id) + 4(user_id) + 4(post_id) + 256(message) + 8(time) = 276 байт```
  <br><br>
  Согласно [источнику](https://blog.cybermarketing.ru/vovlechennost-instagram/), медиана числа комментариев к посту равна 4, тогда таблица займет:<br>
  ```276 * 160000000000 * 4 / 1024^3  = 164 509 Гб```
  <br><br>

* Лайки:<br>
  Одна запись в таблице займет:<br>
  ```4(user_id) + 4(post_id) = 8 байт```
  <br><br>
  Согласно [источнику](https://blog.cybermarketing.ru/vovlechennost-instagram/), медиана количества лайков к посту равна 100, тогда таблица займет:<br>
  ```8 * 160000000000 * 100 / 1024^3  = 119 210 Гб```
  <br><br>
  
Таким образом, для хранения таблиц потребуется<br>
```1040 + 78083 + 164509 + 119210 = 362 842 Гб```

### 5. Выбор прочих технологий

#### Frontend
Фронтенд будет написан с использованием технологий HTML, CSS, Typescript.
В качестве библиотеки для работы с интерфейсаими будет использоваться React, так как он обеспечивает модульность кода 
и высокую производительность, а также, прост в освоении. Для увеличения уровня абстракции при работе с css, 
воспользуемся Scss(Sass) - метаязыком, основанным на css. В качестве сборщика модулей будем использовать один из наиболее
распространенных инструментов - Webpack

#### Backend
Бэкенд будет иметь микросервисную архитектуру, что позволит легко масштабировать конкретный сервис, а не все приложение,
а также, повысит отказоустойчивость системы. В качестве основного языка будет использоваться Golang, так как он 
обладает строгой типизацией, низким порогом вхождения, многопоточностью и кроссплатформенностью "из коробки", а также, 
высокой производительностью.

#### Протоколы взаимодействия
Для общения между клиентом и сервером выберем протокол HTTP2, так как он бинарный, а также, поддеожиывет одновременную
загрузку большого количества файлов. Сами данные будут передаваться в формате json, так как он прост и поддерживается 
многими языками программирования.

На бэкенде для общения между микросервисами будет использоваться протокол gRPC, а данные будут передаваться в формате 
protobuf, что позволит увеличить скорость общения, так как структуры в protobuf быстрее парсятся и имеют меньший 
размер, в сравнении с другими форматами.

#### Балансировка нагрузки и раздача статики
Для раздачи статики м балансировки нагрузки будет использоваться Nginx, как надежный и высокопроизводительный веб-сервер,
поддерживающий возможность написания собственных модулей, а также, обладающий крупным сообществом.

### 6. Расчет нагрузки и потребного оборудования

#### Балансировка и раздача статики

* Исходя из [документации](https://www.nginx.com/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers/) nginx,
приняв, что размер пакета равен 100 Кб можем подсчитать, что для балансировки 1 174 769 RPS для HTTPS соединений 
нужно ```1 174 769 / 89 842 = ~ 14```серверов.
* Для раздачи 1360 Гб/сек, учитывая, что будут использоваться сетевые карточки на 10 Гб/сек, необходимо ~ 136 серверов
* Считая, что в среднем, сервисом пользуется ~6000 человек в секунду, согласно [источнику](https://www.nginx.com/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers/), 
чтобы поддерживать необходимый CPS, с учетом HTTPS соединения, нужен 1 сервер
  
Возьмем наибольшее из полученных значений и, с учетом запаса в 30 - 40%, получим, что для балансировки и раздачи статики 
требуется 180 серверов со следующей конфигурацией:

|CPU(cores)|RAM (Gb)|SSD (Gb)|Network (Gbps)|
|:---:|:---:|:---:|:---:|
|36|32|128|10|

#### Сервис авторизации/регистрации

* Для хранения данных пользователей необходимо 1040 Гб. Если использовать SSD на 2 Тб, тогда для хранения данных хватит
  1 сервера.
* Согласно расчетам, проведенным в п.2, сервис авторизации должен держать нагрузку в 23 151 RPS. Приняв, что средний RPS
  на ядро для PostgreSql ~ 500 RPS, получаем, что необходимо ```23 151 / 500 / 36 = ~ 2``` сервера.
* Согласно расчетам, проведенным в п.2, нагрузка на сеть для сервиса авторизации составляет 28 Мбит/с. Поставив на сервер
  сетевую карту на 100 Мб/сек, получим, что для поддержания работы требуется 1 сервер.

Для обеспечения отказоустойчивости, возьмем 2 сервера. С учетом 1 master 2 slave, получаем 6 серверов со следующими
конфигурациями:

|CPU(cores)|RAM (Gb)|SSD (Tb)|Network (Mbps)|
|:---:|:---:|:---:|:---:|
|36|32|4|100|

#### Хранение сессий

* Для хранения сессий пользователя будет использоваться Redis. Оценивая размер одной записи пары ключ-значение в 128 байт,
получим, что для хранения информации о всех пользователях, нужно ```128 * 1 000 000 000 / 1024^3 = ~ 120 Гб```. Такой объем 
памяти можно поместить в 1 сервер.
* Согласно расчетам, проведенным в п.2, сервис авторизации должен держать нагрузку в 23 151 RPS. Приняв, что средний RPS
на ядро для Redis ~ 10 000 RPS, также получаем, что хватит 1 сервера.
* Нагрузка на сеть составит примерно ```128 * 500000000 / 1024 / (24 * 60 * 60) = ~ 730 Кбит/с```. Поставив на сервер 
сетевую карту на 100 Мб/сек, получим, что для поддержания работы требуется 1 сервер.
  
Для обеспечения отказоустойчивости, возьмем 2 сервера. С учетом 1 master 2 slave, получаем 6 серверов со следующими 
конфигурациями:

|CPU(cores)|RAM (Gb)|SSD (Gb)|Network (Mbps)|
|:---:|:---:|:---:|:---:|
|36|128|128|100|

#### Сервисы создания постов/комментариев/лайков

* Для хранения данных пользователей необходимо ```78083 + 164509 + 119210 = 361 802 Гб``` для постов, комментариев и
  лайков соответственно. Рассчитаем, какой необходим запас по памяти на 3 года работы сервиса:
  * для постов: т.к. в день публикуется 100 000 000 постов, а запись в таблице постов занимает 524 байта получаем:
  ```100 000 000 * 524 * 365 * 3 / 1024^3 = ~ 53 500 Гб```
  * для комментариев: т.к. в день публикуется 86 400 000 комментариев, а запись в таблице постов занимает 276 байт получаем:
    ```86 400 000 * 276 * 365 * 3 / 1024^3 = ~ 24 500 Гб```
  * для лайков: т.к. в день ставится 734 400 000 лайков, а запись в таблице постов занимает 8 байт получаем:
    ```734 400 000 * 8 * 365 * 3 / 1024^3 = ~ 6000 Гб```<br>
    
  Тогда для хранения данных с запасом нужно ```361 802 + 53 500 + 24 500 + 6000 = 445 802 Гб```.
  Считая, что в сервер можно поставить 32 диска, и будут использоваться SSD по 4 Тб, получаем что
  для хранения данных нужно ```445 802 / (4 * 1024) / 32 = 4``` сервера.
* Согласно расчетам, проведенным в п.3, сервис авторизации должен держать нагрузку в ```1158 + 8500 + 1000 = 10 658 RPS```.
  Также, нужно учесть запросы на просмотр постов и комментариев. Предположим, что пользователь читает каждый второй пост,
  тогда дополнительно будет происходить 579 запросов в сервис постов и 500 запросов в сервис комментариев. Итого 
  получается ```10 658 + 579 + 500 = 11 737 RPS```.
  Исходя из предположения, что на 1 запрос приходится 1 обращение в БД и приняв, что средний RPS на ядро для 
  PostgreSql ~ 500 RPS, получаем, что необходимо ```11 737 / 500 / 36 = ~ 1``` сервер.
* Согласно расчетам, проведенным в п.3, нагрузка на сеть для сервиса авторизации составляет 
  ```27.2 Гбит/с + 4.6 Мбит/с + 0.6 Мбит/с = 28 Гбит/с```. Поставив на сервера сетевые карты на 10 Гб/сек, получим, 
  что для поддержания работы требуется 3 сервера.

Для обеспечения отказоустойчивости, возьмем 6 серверов. С учетом 1 master 2 slave, получаем 18 серверов со следующими
конфигурациями:

|CPU(cores)|RAM (Gb)|SSD (Tb)|Network (Gbps)|
|:---:|:---:|:---:|:---:|
|36|32|4 x 32|10|

#### Сервис ленты

* Согласно расчетам, проведенным в п.3, сервис ленты должен держать нагрузку в 3 038 195 RPS.
  Предположим, что из-за вычислений генерации ленты для пользователя, на одно ядро приходится 200 RPS. Тогда рассчитаем 
  количество серверов для сервиса с учетом использования 36-ядерных процессоров: ```3 038 195 / 200 / 36 = 422``` сервера.
* Согласно расчетам, проведенным в п.2, нагрузка на сеть для сервиса ленты составляет 307.44 Гбит/с. 
  Поставив на сервера сетевые карты на 1 Гб/сек, получим, что для поддержания работы требуется 308 серверов.

Возьмем наибольшее из полученных значений и, с учетом запаса в 30 - 40%, получим, что для балансировки и раздачи статики
требуется 550 серверов со следующей конфигурацией:

|CPU(cores)|RAM (Gb)|SSD (Gb)|Network (Gbps)|
|:---:|:---:|:---:|:---:|
|36|32|128|1|

#### Хранение фотографий

* Для раздачи фото будем использовать nginx. Тогда исходя из [документации](https://www.nginx.com/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers/) nginx,
  приняв, что размер пакета равен 100 Кб, а в процессоре 8 ядер, можем подсчитать, что для балансировки 8 547 454 RPS для HTTPS соединений
  нужно ```8 547 454 / 38 900 = ~ 220```серверов.

* Необходимо раздавать 9019.64 Гб/сек, при использовании обычных сетевых карт на 10 Гб/сек, понадобится около 900 
  серверов. Чтобыументщить это количество, можем использовать сетевые карточки на 40 Гб/сек 
  (например, Intel XL710 40 GbE QSFP+ (rev 01)), тогда будет необходимо ~ 226 серверов.

* Для обеспечения отказоустойчивости и целостности данных воспользуемся технологией RAID 10, она также обеспечит 
  достаточную производительность. Для этого потребуется в 4 раза больше дисков.

* Для хранения фотографий пользователей, согласно п.4 необходимо 312 500 000 Гб. Рассчитаем, какой необходим запас по 
  памяти на 3 года работы сервиса. Учитывая, что ежедневно публикуется 100 млн. постов, и считая, что в среднем в посте 
  будет публиковаться по 1 фото, а средний размер фото равен 3 мб, получим: ```100 000 000 * 2 * 365 * 3 / 1024 = 213 867 188 Гб```
  Тогда всего выйдет ```312 500 000 + 213 867 188 = 562 367 188 Гб```.
  Так как только около 10% постов пользуются популярностью, чтобы уменьшить затраты SSD, будем хранить часть фото на 
  серверах с HDD. Разбиение фото можно проводить по количеству лайков в посте. Примем, что 10% фото будет храниться на 
  серверах с SSD, тогда, при использовании стоек на 90 дисков и SSD на 4 Тб, потребуется 
  ```0.1 * 562 367 188 / (4 * 1024) / 90 = 153``` сервера. С учетом использования RAID 10 - 612 серверов. 
  А для остальных 90% фото, при условии использования стоек на 90 дисков и HDD на 20 Тб нужно 
  ```0.9 * 562 367 188 / (20 * 1024) / 90 = 275``` сервера. С учетом использования RAID 10 - 1100 серверов.
  
Итого, получаем 612 серверов с конфигурациями:

|CPU(cores)|RAM (Gb)|SSD (Tb)|Network (Gbps)|
|:---:|:---:|:---:|:---:|
|8|32|4 x 90|40|

и 1100 серверов с конфигурациями:

|CPU(cores)|RAM (Gb)|HDD (Tb)|Network (Gbps)|
|:---:|:---:|:---:|:---:|
|8|32|20 x 90|40|

Итого:

|                                 |   CPU   |  RAM  |  SSD  |  HDD  | Network | Кол-во |
|---------------------------------|---------|-------|-------|-------|---------|--------|
| Балансировка и статика          | 36 cores | 32GB | 128GB | 0 | 10Gbps | 180 |
| Сервис авторизации/регистрации  | 36 cores | 32GB | 4Tb | 0 | 100Mbps | 6 |
| Хранение сессий                 | 36 cores | 128GB | 128GB | 0 | 100Mbps | 6 |
| Сервисы создания постов/комментариев/лайков | 36 cores | 32GB | 4Tb x 32 | 0 | 10Gbps | 18 | 
| Сервис ленты                    | 36 cores | 32GB | 128GB | 0 | 1Gbps | 550 |
| Хранение фотографий             | 8 cores | 32GB | 4Tb x 90 | 0 | 40Gbps | 612 |
| Хранение фотографий             | 8 cores | 32GB | 0 | 20Tb x 90 | 40Gbps | 1100 |
| Итого                           | |  | | | |  2472  |

### 7. Выбор хостинга / облачного провайдера и расположения серверов

Так как облачные решения и аренда оборудования для таких больших проектов стоят слишком дорого, бедем использовать свои 
датацентры. Так как клиенты обращаются в основном с территории Европы и Америки, расположим по одному датацентру в этих 
регионах. Тогда можем расположить один датацентр во Франкфурте и один в Торонто и поделить сервера между ними пополам.

